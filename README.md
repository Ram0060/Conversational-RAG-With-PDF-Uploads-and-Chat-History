# ğŸ§  Conversational RAG with PDF Uploads and Chat History

This project is a **Conversational Retrieval-Augmented Generation (RAG) app** built with **Streamlit**. It lets users upload one or more PDF documents and then chat with the contents in a context-aware, multi-turn dialogue.

Powered by:
- ğŸ“„ PDF ingestion with LangChain loaders
- ğŸ” Chunking + Embeddings using HuggingFace + ChromaDB
- ğŸ¤– LLM via Groq's blazing-fast Gemma-2B model
- ğŸ§  Memory-augmented prompts to keep track of conversation history

---

## ğŸš€ Features

- ğŸ“š Upload one or more PDF files
- ğŸ§© Splits documents into chunks using `RecursiveCharacterTextSplitter`
- ğŸ§  Embeds chunks using `all-MiniLM-L6-v2` from HuggingFace
- ğŸ’¾ Stores embeddings in a local Chroma vector store
- ğŸ”„ Reformulates follow-up questions using chat history
- ğŸ¤– Answers questions using retrieved context and LLM (Gemma 2B via Groq API)
- ğŸ’¬ Maintains chat history per session
- ğŸ” Supports secure Groq API key input in the frontend

---

## ğŸ“¦ Tech Stack

| Tool        | Purpose                            |
|-------------|------------------------------------|
| Streamlit   | UI for chat + file upload          |
| LangChain   | Orchestration + memory management  |
| ChromaDB    | Local vector store for retrieval   |
| HuggingFace | Embeddings model (`MiniLM`)        |
| Groq        | LLM backend (Gemma-2B-IT)           |
| PyPDFLoader | PDF parsing                        |

---